{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script para limpar os discursos da base:\n",
    "- remover stopwords\n",
    "- remover pontuação\n",
    "- remover caracteres especiais\n",
    "- remover palavras/termos muito comuns, por exemplo, \"Sr. Presidente\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from unicodedata import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stop_words(data, list_stop_words = None):\n",
    "    \"\"\"\n",
    "    Função para remover stopwords em português\n",
    "    \"\"\"\n",
    "    print('  Remove Stop Words')\n",
    "\n",
    "    #list_stop_words = set(stopwords.words('portuguese'))\n",
    "    if list_stop_words != None:\n",
    "        output = []\n",
    "        for sentence in data:\n",
    "            temp_list = []\n",
    "            for word in sentence.split():\n",
    "                if word.lower() not in list_stop_words:\n",
    "                    temp_list.append(word)\n",
    "            output.append(' '.join(temp_list))\n",
    "\n",
    "        data = pd.Series(output)    \n",
    "    \n",
    "    return data\n",
    "\n",
    "def remove_punct(data):\n",
    "    \"\"\"\n",
    "    Função para remover pontuações\n",
    "    \"\"\"\n",
    "    print('  Remove Punction')\n",
    "\n",
    "    puncts = [\"\\\\\" +s for s in string.punctuation]\n",
    "    puncts = '|'.join(puncts)\n",
    "    data = data.replace(puncts,' ',regex=True)    \n",
    "    return data\n",
    "\n",
    "def remove_special_caract(array_data):\n",
    "    \"\"\"\n",
    "    Função para substituir caracteres especiais\n",
    "    \"\"\"\n",
    "    print('  Remove Special Caract')\n",
    "    data = [normalize('NFKD', data).encode('ASCII', 'ignore').decode('ASCII') for data in array_data]\n",
    "    return data\n",
    "\n",
    "def remove_patter_terms(data):\n",
    "    \"\"\"\n",
    "    Função para remover orações que há em todos os discursos, como \"senhor presidente\", \"senhora(s) deputadas\"\n",
    "    \"\"\"\n",
    "    #print(data)\n",
    "    pattern = \"^(.+?)-\\sSr|(((O?\\s?SR\\.?\\s+?)|(A?\\s?SRA\\.?\\s+?))(\\s+DEPUTADO|\\s+DEPUTADA|\\s+PRESIDENTE|\\s+PRESIDENTA)?)|\\\n",
    "              (SR\\.?\\s+?)|(SRA\\.?\\s+?)|srs|sras|(presidente|deputado(s)|deputada(s))\"\n",
    "    \n",
    "    data = re.sub(pattern, '',data, flags = re.IGNORECASE)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def clean_text(data):\n",
    "    \"\"\"\n",
    "    Função para fazer pre-processamento dos textos\n",
    "    \"\"\"\n",
    "    print('Cleaning text...')\n",
    "    data.isnull().sum()\n",
    "    data =  data.apply(remove_patter_terms)\n",
    "    \n",
    "    data = remove_punct(data)\n",
    "    data = data.str.lower()\n",
    "    \n",
    "    list_stop_words = remove_special_caract(stopwords.words('portuguese'))\n",
    "    list_stop_words.extend(['ser','ja','ha','exa','ainda','ate','todo','todos','toda','todas','devem'])\n",
    "    list_stop_words = set(list_stop_words)\n",
    "    data = remove_stop_words(data, list_stop_words)\n",
    "    \n",
    "    #data = data.replace('\\s+',' ',regex=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = \"../data/csvs/\"\n",
    "discursos = pd.read_csv(directory+'discursos_plen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FILE                4\n",
       "ORIGINAL_CONTENT    4\n",
       "CLEAN_CONTENT       4\n",
       "SESSION_TYPE        0\n",
       "SESSION_DATE        0\n",
       "MONTH               0\n",
       "YEAR                0\n",
       "SPEAKER_COUNT       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discursos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discursos = discursos.dropna()\n",
    "discursos.index = [i for i in range(0,len(discursos))] #loc[discursos.CLEAN_CONTENT.isna(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FILE                0\n",
       "ORIGINAL_CONTENT    0\n",
       "CLEAN_CONTENT       0\n",
       "SESSION_TYPE        0\n",
       "SESSION_DATE        0\n",
       "MONTH               0\n",
       "YEAR                0\n",
       "SPEAKER_COUNT       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discursos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113154\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 113154 entries, 0 to 113153\n",
      "Data columns (total 8 columns):\n",
      "FILE                113154 non-null object\n",
      "ORIGINAL_CONTENT    113154 non-null object\n",
      "CLEAN_CONTENT       113154 non-null object\n",
      "SESSION_TYPE        113154 non-null object\n",
      "SESSION_DATE        113154 non-null object\n",
      "MONTH               113154 non-null int64\n",
      "YEAR                113154 non-null int64\n",
      "SPEAKER_COUNT       113154 non-null int64\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "print(len(discursos))\n",
    "discursos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#discursos = discursos.reindex([i for i in range(0,len(discursos))])#.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discursos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discursos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Remove Special Caract\n"
     ]
    }
   ],
   "source": [
    "# retirando caracteres especiais das stopwords, porque o texto está sem!!\n",
    "list_stop_words = remove_special_caract(stopwords.words('portuguese'))\n",
    "\n",
    "# inserindo mais palavras pra ser removidas\n",
    "list_stop_words.extend(['ser','ja','ha','exa','ainda','ate','todo','todos','toda','todas','devem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text...\n",
      "  Remove Punction\n",
      "  Remove Special Caract\n",
      "  Remove Stop Words\n"
     ]
    }
   ],
   "source": [
    "discursos.loc[:,'CLEAN_CONTENT'] = clean_text(discursos.loc[:,'CLEAN_CONTENT'])\n",
    "#discursos.iloc[57646:57647,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE                0\n",
      "ORIGINAL_CONTENT    0\n",
      "CLEAN_CONTENT       0\n",
      "SESSION_TYPE        0\n",
      "SESSION_DATE        0\n",
      "MONTH               0\n",
      "YEAR                0\n",
      "SPEAKER_COUNT       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(discursos.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd de Registros por ANO:\n",
      "2015    7971\n",
      "2017    7923\n",
      "2013    7923\n",
      "2007    7264\n",
      "2009    7110\n",
      "2003    6726\n",
      "2016    6624\n",
      "2011    6464\n",
      "2008    5945\n",
      "2019    5777\n",
      "2012    5666\n",
      "2005    5620\n",
      "2001    5445\n",
      "2004    5442\n",
      "2014    4909\n",
      "2018    4701\n",
      "2006    4554\n",
      "2010    4247\n",
      "2002    2843\n",
      "Name: YEAR, dtype: int64\n",
      "\n",
      "Qtd Total de registros:113154 \n"
     ]
    }
   ],
   "source": [
    "print('Qtd de Registros por ANO:\\n{}\\n\\nQtd Total de registros:{} '.format(discursos.YEAR.value_counts(),len(discursos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 113154 entries, 0 to 113153\n",
      "Data columns (total 8 columns):\n",
      "FILE                113154 non-null object\n",
      "ORIGINAL_CONTENT    113154 non-null object\n",
      "CLEAN_CONTENT       113154 non-null object\n",
      "SESSION_TYPE        113154 non-null object\n",
      "SESSION_DATE        113154 non-null object\n",
      "MONTH               113154 non-null int64\n",
      "YEAR                113154 non-null int64\n",
      "SPEAKER_COUNT       113154 non-null int64\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "discursos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## salvando dados limpos em uma nova base\n",
    "discursos.to_csv(directory+'discursos_plen_limpo.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
